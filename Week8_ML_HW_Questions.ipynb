{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 8 Machine Learning Homework\n",
        "\n",
        "## Instructions\n",
        "Complete all exercises below by writing code in the cells provided. Focus on implementing and understanding the sigmoid function and evaluation metrics.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "S6-F0OzF2Its"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Sigmoid Function Implementation\n",
        "\n",
        "Implement the sigmoid function from scratch and visualize it."
      ],
      "metadata": {
        "id": "9fkO3LjH2Nl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Implement the sigmoid function\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid function for input x\n",
        "\n",
        "    Parameters:\n",
        "    x: input value or array\n",
        "\n",
        "    Returns:\n",
        "    sigmoid of x\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Generate x values from -10 to 10\n",
        "x_values = np.linspace(-10, 10, 100)\n",
        "\n",
        "# TODO: Compute sigmoid values for x_values\n",
        "# y_values = ?\n",
        "\n",
        "# TODO: Create a plot of the sigmoid function\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Your plotting code here\n",
        "plt.title('Sigmoid Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('sigmoid(x)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# TODO: Test your implementation with specific values\n",
        "test_values = [-5, -2, 0, 2, 5]\n",
        "print(\"Sigmoid function test:\")\n",
        "for val in test_values:\n",
        "    # Print sigmoid of each test value\n",
        "    pass"
      ],
      "metadata": {
        "id": "3PZsvY6k2Wkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Logistic Regression Probability Calculation\n",
        "\n",
        "Use the sigmoid function to calculate class probabilities."
      ],
      "metadata": {
        "id": "oVBUnJL92h9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample feature values and model coefficients\n",
        "feature1 = 1.5\n",
        "feature2 = -0.8\n",
        "bias = 0.5\n",
        "coef1 = 0.8\n",
        "coef2 = -0.3\n",
        "\n",
        "# TODO: Calculate the linear combination z\n",
        "# z = ?\n",
        "\n",
        "# TODO: Use sigmoid to calculate probability of class 1\n",
        "# probability = ?\n",
        "\n",
        "print(f\"Linear combination z: {z:.4f}\")\n",
        "print(f\"Probability of class 1: {probability:.4f}\")\n",
        "\n",
        "# TODO: Based on a threshold of 0.5, make a prediction\n",
        "# prediction = ?\n",
        "print(f\"Predicted class: {prediction}\")\n",
        "\n",
        "# TODO: Create a function that takes features, coefficients, and bias\n",
        "# and returns both probability and prediction\n",
        "def predict_probability(features, coefficients, bias, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate probability and prediction using sigmoid function\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test the function\n",
        "test_features = [1.5, -0.8]\n",
        "test_coefficients = [0.8, -0.3]\n",
        "test_bias = 0.5\n",
        "\n",
        "# prob, pred = predict_probability(test_features, test_coefficients, test_bias)\n",
        "# print(f\"\\nTest - Probability: {prob:.4f}, Prediction: {pred}\")"
      ],
      "metadata": {
        "id": "SEF9_Lok2mj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Confusion Matrix Implementation\n",
        "\n",
        "Implement a confusion matrix calculation from scratch."
      ],
      "metadata": {
        "id": "owEoPTz23AoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample true labels and predictions\n",
        "y_true = [0, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
        "y_pred = [0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
        "\n",
        "# TODO: Calculate TP, TN, FP, FN from scratch\n",
        "def calculate_confusion_matrix(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate confusion matrix components\n",
        "    \"\"\"\n",
        "    TP = TN = FP = FN = 0\n",
        "    # Your code here\n",
        "    return TP, TN, FP, FN\n",
        "\n",
        "# TODO: Test your function\n",
        "# TP, TN, FP, FN = calculate_confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix Components:\")\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "# TODO: Create a visualization of the confusion matrix\n",
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = np.array([[TN, FP], [FN, TP]])\n",
        "# Your plotting code here\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3EKQmDmC3IPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4: Classification Metrics Calculation\n",
        "\n",
        "Implement accuracy, precision, recall, and F1-score from scratch.\n"
      ],
      "metadata": {
        "id": "vGFu3IuX3V-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement classification metrics using confusion matrix components\n",
        "def calculate_metrics(TP, TN, FP, FN):\n",
        "    \"\"\"\n",
        "    Calculate classification metrics from confusion matrix components\n",
        "    \"\"\"\n",
        "    accuracy = precision = recall = f1 = 0\n",
        "\n",
        "    # Your code here\n",
        "    # Calculate accuracy\n",
        "    # Calculate precision\n",
        "    # Calculate recall\n",
        "    # Calculate F1-score\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# TODO: Calculate metrics using the confusion matrix from Exercise 3\n",
        "# accuracy, precision, recall, f1 = calculate_metrics(TP, TN, FP, FN)\n",
        "\n",
        "print(\"\\nClassification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "bGKdn5im3a0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Week 8 Machine Learning Homework\n",
        "\n",
        "## Instructions\n",
        "# Complete all exercises below by writing code in the cells provided.\n",
        "# Focus on implementing and understanding the sigmoid function and evaluation metrics.\n",
        "\n",
        "# ---\n",
        "# ### Exercise 1: Sigmoid Function Implementation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Implement the sigmoid function\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid function for input x\n",
        "\n",
        "    Parameters:\n",
        "    x: input value or array\n",
        "\n",
        "    Returns:\n",
        "    sigmoid of x\n",
        "    \"\"\"\n",
        "    x = np.array(x)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Generate x values from -10 to 10\n",
        "x_values = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Compute sigmoid values for x_values\n",
        "y_values = sigmoid(x_values)\n",
        "\n",
        "# Create a plot of the sigmoid function\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_values, y_values)\n",
        "plt.title('Sigmoid Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('sigmoid(x)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Test your implementation with specific values\n",
        "test_values = [-5, -2, 0, 2, 5]\n",
        "print(\"Sigmoid function test:\")\n",
        "for val in test_values:\n",
        "    print(f\"x = {val}, sigmoid(x) = {sigmoid(val):.4f}\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# Exercise 2: Logistic Regression Probability Calculation\n",
        "\n",
        "# Sample feature values and model coefficients\n",
        "feature1 = 1.5\n",
        "feature2 = -0.8\n",
        "bias = 0.5\n",
        "coef1 = 0.8\n",
        "coef2 = -0.3\n",
        "\n",
        "# Calculate the linear combination z\n",
        "z = coef1 * feature1 + coef2 * feature2 + bias\n",
        "\n",
        "# Use sigmoid to calculate probability of class 1\n",
        "probability = sigmoid(z)\n",
        "\n",
        "print(f\"Linear combination z: {z:.4f}\")\n",
        "print(f\"Probability of class 1: {probability:.4f}\")\n",
        "\n",
        "# Based on a threshold of 0.5, make a prediction\n",
        "prediction = 1 if probability >= 0.5 else 0\n",
        "print(f\"Predicted class: {prediction}\")\n",
        "\n",
        "# Create a function that takes features, coefficients, and bias\n",
        "# and returns both probability and prediction\n",
        "def predict_probability(features, coefficients, bias, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate probability and prediction using sigmoid function\n",
        "    \"\"\"\n",
        "    features = np.array(features)\n",
        "    coefficients = np.array(coefficients)\n",
        "    z = np.dot(features, coefficients) + bias\n",
        "    prob = sigmoid(z)\n",
        "    pred = 1 if prob >= threshold else 0\n",
        "    return prob, pred\n",
        "\n",
        "# Test the function\n",
        "test_features = [1.5, -0.8]\n",
        "test_coefficients = [0.8, -0.3]\n",
        "test_bias = 0.5\n",
        "\n",
        "prob, pred = predict_probability(test_features, test_coefficients, test_bias)\n",
        "print(f\"\\nTest - Probability: {prob:.4f}, Prediction: {pred}\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# Exercise 3: Confusion Matrix Implementation\n",
        "\n",
        "# Sample true labels and predictions\n",
        "y_true = [0, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
        "y_pred = [0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
        "\n",
        "# Calculate TP, TN, FP, FN from scratch\n",
        "def calculate_confusion_matrix(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate confusion matrix components\n",
        "    \"\"\"\n",
        "    TP = TN = FP = FN = 0\n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        if yt == 1 and yp == 1:\n",
        "            TP += 1\n",
        "        elif yt == 0 and yp == 0:\n",
        "            TN += 1\n",
        "        elif yt == 0 and yp == 1:\n",
        "            FP += 1\n",
        "        elif yt == 1 and yp == 0:\n",
        "            FN += 1\n",
        "    return TP, TN, FP, FN\n",
        "\n",
        "# Test your function\n",
        "TP, TN, FP, FN = calculate_confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix Components:\")\n",
        "print(f\"True Positives (TP): {TP}\")\n",
        "print(f\"True Negatives (TN): {TN}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "\n",
        "# Create a visualization of the confusion matrix\n",
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = np.array([[TN, FP], [FN, TP]])\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Pred 0', 'Pred 1'],\n",
        "            yticklabels=['True 0', 'True 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ---\n",
        "# Exercise 4: Classification Metrics Calculation\n",
        "\n",
        "# Implement classification metrics using confusion matrix components\n",
        "def calculate_metrics(TP, TN, FP, FN):\n",
        "    \"\"\"\n",
        "    Calculate classification metrics from confusion matrix components\n",
        "    \"\"\"\n",
        "    total = TP + TN + FP + FN\n",
        "    accuracy = (TP + TN) / total if total > 0 else 0\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Calculate metrics using the confusion matrix from Exercise 3\n",
        "accuracy, precision, recall, f1 = calculate_metrics(TP, TN, FP, FN)\n",
        "\n",
        "print(\"\\nClassification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "IIvJp_MnS_7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}