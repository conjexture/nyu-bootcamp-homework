{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9f2c741-b572-4554-9fac-7a31eadfb7e9",
      "metadata": {
        "id": "c9f2c741-b572-4554-9fac-7a31eadfb7e9"
      },
      "source": [
        "# (Homework) Week 7 - DataScience Bootcamp Fall 2025\n",
        "\n",
        "All solution cells are replaced with `# TODO` placeholders so you can fill them in.\n",
        "\n",
        "**Name:Saul Veras** \\\n",
        "**Email:sv3253@nyu.edu**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d573e681-e12c-4dd1-89af-a4b3b6aaeb22",
      "metadata": {
        "id": "d573e681-e12c-4dd1-89af-a4b3b6aaeb22"
      },
      "source": [
        "## Problem A: Bayesian Dice Game (Posterior Inference)\n",
        "\n",
        "You are playing a dice game at a carnival. The operator has **three dice**, each with different biases for rolling a six:\n",
        "\n",
        "| Die | P(6) | P(1–5) |\n",
        "|-----|------|--------|\n",
        "| A   | 0.10 | 0.90   |\n",
        "| B   | 0.30 | 0.70   |\n",
        "| C   | 0.60 | 0.40   |\n",
        "\n",
        "Before each round, the operator secretly picks one die at random (each equally likely). He then rolls it **10 times** and tells you how many sixes appeared.\n",
        "\n",
        "Your job is to infer which die was used using **Bayes’ Theorem**:\n",
        "\n",
        "$$ P(Die|k) = \\frac{P(k|Die)P(Die)}{\\sum_{d} P(k|d)P(d)} $$\n",
        "\n",
        "where $P(k|Die)$ follows a Binomial (n=10, p_i) distribution.\n",
        "\n",
        "**Tasks:**\n",
        "1. Simulate the experiment by picking a random die and rolling it 10 times.\n",
        "2. Compute posterior probabilities for each die given observed sixes.\n",
        "3. Plot likelihoods and posterior probabilities.\n",
        "4. Evaluate inference accuracy over 100 rounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62652645-00ee-4443-add5-26e6e888506a",
      "metadata": {
        "id": "62652645-00ee-4443-add5-26e6e888506a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# Dice setup\n",
        "dice_probs = {'A': 0.1, 'B': 0.3, 'C': 0.6}\n",
        "dice_names = list(dice_probs.keys())\n",
        "prior = np.array([1/3, 1/3, 1/3])  # uniform prior over A, B, C\n",
        "n_rolls = 10\n",
        "\n",
        "# Compute binomial probability mass function\n",
        "def binomial_prob(n, k, p):\n",
        "    return math.comb(n, k) * (p**k) * ((1-p)**(n-k))\n",
        "\n",
        "def simulate_round():\n",
        "    # pick a die at random according to the prior (uniform)\n",
        "    idx = np.random.choice(len(dice_names))\n",
        "    true_die = dice_names[idx]\n",
        "    p = dice_probs[true_die]\n",
        "    # sample number of sixes from Binomial(n_rolls, p)\n",
        "    k = np.random.binomial(n_rolls, p)\n",
        "    return true_die, k\n",
        "\n",
        "def posterior_given_k(k):\n",
        "    likelihoods = []\n",
        "    for die in dice_names:\n",
        "        p = dice_probs[die]\n",
        "        likelihoods.append(binomial_prob(n_rolls, k, p))\n",
        "    likelihoods = np.array(likelihoods)\n",
        "    unnormalized = likelihoods * prior\n",
        "    # normalize\n",
        "    if unnormalized.sum() == 0:\n",
        "        # fallback (shouldn't really happen with these params)\n",
        "        return prior.copy()\n",
        "    return unnormalized / unnormalized.sum()\n",
        "\n",
        "# Example run\n",
        "true_die, k = simulate_round()\n",
        "posterior = posterior_given_k(k)\n",
        "\n",
        "print(f\"Observed {k} sixes out of {n_rolls} rolls\")\n",
        "for die, p in zip(dice_names, posterior):\n",
        "    print(f\"P({die} | {k} sixes) = {p:.3f}\")\n",
        "print(f\"True die: {true_die}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b121113b-6352-4043-98f1-17e6bd65d6a5",
      "metadata": {
        "id": "b121113b-6352-4043-98f1-17e6bd65d6a5"
      },
      "source": [
        "## Problem B: Linear Regression\n",
        "Given x=[-2,-1,0,1,2] and y=[7,4,3,4,7]. Fit a linear model using the normal equation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87afafd8-9610-4d4d-b3b4-07a366849346",
      "metadata": {
        "id": "87afafd8-9610-4d4d-b3b4-07a366849346"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([-2, -1, 0, 1, 2])\n",
        "y = np.array([7, 4, 3, 4, 7])\n",
        "\n",
        "X = np.c_[np.ones(len(x)), x]          # design matrix with bias term\n",
        "theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "y_pred = X @ theta\n",
        "mse_linear = np.mean((y_pred - y)**2)\n",
        "\n",
        "print('Linear theta:', theta, 'MSE:', mse_linear)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ccd6092-5a92-4ea1-8e5f-15d4f622f8fe",
      "metadata": {
        "id": "5ccd6092-5a92-4ea1-8e5f-15d4f622f8fe"
      },
      "source": [
        "## Problem C: Gradient Descent\n",
        "Minimize f(w)=5(w−11)^4. Perform steps with α=1/400 and α=1/4000000. (Print the first 5 steps and visualize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f174f5ac-77c2-45d8-a9b9-5bd29c1959bf",
      "metadata": {
        "id": "f174f5ac-77c2-45d8-a9b9-5bd29c1959bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gradient Descent Function\n",
        "def grad_descent_vals(w0, alpha, steps):\n",
        "    ws = []\n",
        "    fs = []\n",
        "    w = w0\n",
        "    for _ in range(steps):\n",
        "        f = 5 * (w - 11)**4\n",
        "        ws.append(w)\n",
        "        fs.append(f)\n",
        "        grad = 20 * (w - 11)**3    # derivative of 5(w-11)^4\n",
        "        w = w - alpha * grad\n",
        "    return np.array(ws), np.array(fs)\n",
        "\n",
        "# Run for two learning rates\n",
        "hist_140 = grad_descent_vals(13, 1/400, 200)\n",
        "hist_180 = grad_descent_vals(13, 1/4000000, 200)\n",
        "\n",
        "w_hist_140, f_hist_140 = hist_140\n",
        "w_hist_180, f_hist_180 = hist_180\n",
        "\n",
        "# Print first 5 steps for each learning rate\n",
        "print(\"alpha = 1/400, first 5 steps (step, w, f(w)):\")\n",
        "for i in range(5):\n",
        "    print(i, w_hist_140[i], f_hist_140[i])\n",
        "\n",
        "print(\"\\nalpha = 1/4000000, first 5 steps (step, w, f(w)):\")\n",
        "for i in range(5):\n",
        "    print(i, w_hist_180[i], f_hist_180[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3445f364-a922-473b-9da2-fa9a0a72cb6a",
      "metadata": {
        "id": "3445f364-a922-473b-9da2-fa9a0a72cb6a"
      },
      "source": [
        "ALL THE BEST!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}